{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\r\n",
    "import networkx as nx\r\n",
    "import scipy.sparse as sparse\r\n",
    "from sklearn import preprocessing as pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def locally_sensitive_hashing(m, d, w, sigma=1.0):\r\n",
    "    # Compute random projection vector\r\n",
    "    v = np.random.randn(d, 1) * sigma  # / np.random.randn(d, 1)\r\n",
    "\r\n",
    "    # Compute random offset\r\n",
    "    b = w * np.random.rand() * sigma\r\n",
    "\r\n",
    "    # Compute hashes\r\n",
    "    labels = np.floor((np.dot(m, v) + b) / w)\r\n",
    "\r\n",
    "    # Compute label\r\n",
    "    _, indices = np.unique(labels, return_inverse=True)\r\n",
    "\r\n",
    "    return indices\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "def normalize_gram_matrix(x):\r\n",
    "    k = np.reciprocal(np.sqrt(np.diag(x)))\r\n",
    "    k = np.resize(k, (len(k), 1))\r\n",
    "    return np.multiply(x, k.dot(k.T))\r\n",
    "\r\n",
    "\r\n",
    "def compute_coloring(M, colors, log_primes):\r\n",
    "    log_prime_colors = np.array([log_primes[i] for i in colors], dtype=np.float64)\r\n",
    "    colors = colors + M.dot(log_prime_colors)\r\n",
    "\r\n",
    "    # Round numbers to avoid numerical problems\r\n",
    "    colors = np.round(colors, decimals=10)\r\n",
    "\r\n",
    "    _, colors = np.unique(colors, return_inverse=True)\r\n",
    "\r\n",
    "    return colors\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\r\n",
    "import itertools as it\r\n",
    "import numpy as np\r\n",
    "import scipy.sparse.csr as csr\r\n",
    "import scipy.sparse.lil as lil\r\n",
    "\r\n",
    "def shortest_path_kernel(graph_db, hashed_attributes, *kwargs):\r\n",
    "    use_labels = kwargs[0]\r\n",
    "\r\n",
    "    num_vertices = 0\r\n",
    "    for g in graph_db:\r\n",
    "        num_vertices += g.number_of_nodes()\r\n",
    "\r\n",
    "    offset = 0\r\n",
    "    graph_indices = []\r\n",
    "    colors_0 = np.zeros(num_vertices, dtype=np.int64)\r\n",
    "\r\n",
    "    # Get labels (colors) from all graph instances\r\n",
    "    offset = 0\r\n",
    "    for g in graph_db:\r\n",
    "        graph_indices.append((offset, offset + g.number_of_nodes() - 1))\r\n",
    "\r\n",
    "        if use_labels == 1:\r\n",
    "            for i, label in enumerate(nx.get_node_attributes(g,use_labels).values()):\r\n",
    "                colors_0[i + offset] = label\r\n",
    "\r\n",
    "        offset += g.number_of_nodes()\r\n",
    "    _, colors_0 = np.unique(colors_0, return_inverse=True)\r\n",
    "\r\n",
    "    colors_1 = hashed_attributes\r\n",
    "\r\n",
    "    triple_indices = []\r\n",
    "    triple_offset = 0\r\n",
    "    triples = []\r\n",
    "\r\n",
    "    # Solve APSP problem for every graphs in graph data base\r\n",
    "    for i, g in enumerate(graph_db):\r\n",
    "        # a = gt.adjacency(g)\r\n",
    "        M = dict(nx.all_pairs_shortest_path_length(g))\r\n",
    "\r\n",
    "        # index is a tuple giving index of first and last node for graph h\r\n",
    "        index = graph_indices[i]\r\n",
    "\r\n",
    "        if use_labels:\r\n",
    "            l = colors_0[index[0]:index[1] + 1]\r\n",
    "            h = colors_1[index[0]:index[1] + 1]\r\n",
    "        else:\r\n",
    "            h = colors_1[index[0]:index[1] + 1]\r\n",
    "        d = len(M)\r\n",
    "\r\n",
    "        # For each pair of vertices collect labels, hashed attributes, and shortest-path distance\r\n",
    "        pairs = list(it.product(range(d), repeat=2))\r\n",
    "        if use_labels:\r\n",
    "            t = [hash((l[k], h[k], l[j], h[j], M[k][j])) for (k, j) in pairs if (k != j or ~np.isinf(M[k][j]))]\r\n",
    "        else:\r\n",
    "            t = [hash((h[k], h[j], M[k][j])) for (k, j) in pairs if (k != j or ~np.isinf(M[k][j]))]\r\n",
    "\r\n",
    "        triples.extend(t)\r\n",
    "\r\n",
    "        triple_indices.append((triple_offset, triple_offset + len(t) - 1))\r\n",
    "        triple_offset += len(t)\r\n",
    "\r\n",
    "    _, colors = np.unique(triples, return_inverse=True)\r\n",
    "    m = np.amax(colors) + 1\r\n",
    "\r\n",
    "    # Compute feature vectors\r\n",
    "    feature_vectors = []\r\n",
    "    for i, index in enumerate(triple_indices):\r\n",
    "        feature_vectors.append(np.bincount(colors[index[0]:index[1] + 1], minlength=m))\r\n",
    "\r\n",
    "\r\n",
    "    #if not compute_gram_matrix:\r\n",
    "    return lil.lil_matrix(feature_vectors, dtype=np.float64) # each feature vector will be row\r\n",
    "    # else:\r\n",
    "    #     # Make feature vectors sparse\r\n",
    "    #     gram_matrix = csr.csr_matrix(feature_vectors, dtype=np.float64) # each feature vector will be row\r\n",
    "    #     # Compute gram matrix\r\n",
    "    #     gram_matrix = gram_matrix.dot(gram_matrix.T)\r\n",
    "\r\n",
    "    #     gram_matrix = gram_matrix.toarray()\r\n",
    "\r\n",
    "    #     if normalize_gram_matrix:\r\n",
    "    #         return normalize_gram_matrix(gram_matrix)\r\n",
    "    #     else:\r\n",
    "    #         return gram_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "5\n",
      "5\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "import sys\r\n",
    "#currentdir = os.path.dirname(os.path.realpath(__file__))\r\n",
    "#parentdir = os.path.dirname(currentdir)\r\n",
    "#sys.path.append(parentdir)\r\n",
    "#parentdir = os.path.dirname(parentdir)\r\n",
    "sys.path.append(\"../\")\r\n",
    "import MMDforGraphs as mg\r\n",
    "from importlib import reload  \r\n",
    "foo = reload(mg)\r\n",
    "nr_nodes_1 = 30\r\n",
    "nr_nodes_2 = 30\r\n",
    "n = 3\r\n",
    "m = 3\r\n",
    "\r\n",
    "\r\n",
    "average_degree = 6\r\n",
    "\r\n",
    "\r\n",
    "# bg1 = mg.BinomialGraphs(n, nr_nodes_1, average_degree, l = 'samelabels')\r\n",
    "# bg1 = mg.BinomialGraphs(n, nr_nodes_1, average_degree, l = 'degreelabels')\r\n",
    "bg1 = mg.BinomialGraphs(n, nr_nodes_1, average_degree, a = 'normattr', l = 'degreelabels' )\r\n",
    "bg1.Generate()\r\n",
    "bg2 = mg.BinomialGraphs(m, nr_nodes_2, average_degree+6, a = 'normattr', l = 'degreelabels', loc = 5)\r\n",
    "bg2.Generate()\r\n",
    "\r\n",
    "X = bg1.Gs + bg2.Gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimension is 1\n"
     ]
    }
   ],
   "source": [
    "\r\n",
    "num_vertices = 0\r\n",
    "for g in X:\r\n",
    "    num_vertices += g.number_of_nodes()\r\n",
    "n = len(X)\r\n",
    "\r\n",
    "g = X[0]\r\n",
    "tmp = nx.get_node_attributes(g,'attr')\r\n",
    "dim_attributes = len(tmp[0])\r\n",
    "print(f'dimension is {dim_attributes}')\r\n",
    "colors_0 = np.zeros([num_vertices, dim_attributes])\r\n",
    "offset = 0\r\n",
    "\r\n",
    "gram_matrix = np.zeros([n, n])\r\n",
    "\r\n",
    "# Get attributes from all graph instances\r\n",
    "graph_indices = []\r\n",
    "for g in X:\r\n",
    "    for i, attr in enumerate(nx.get_node_attributes(g,'attr').values()):\r\n",
    "        colors_0[i + offset] = attr\r\n",
    "\r\n",
    "    graph_indices.append((offset, offset + g.number_of_nodes() - 1))\r\n",
    "    offset += g.number_of_nodes()\r\n",
    "\r\n",
    "# Normalize attributes: center to the mean and component wise scale to unit variance\r\n",
    "if True:\r\n",
    "    colors_0 = pre.scale(colors_0, axis=0)\r\n",
    "\r\n",
    "colors_hashed = locally_sensitive_hashing(colors_0, dim_attributes, 0.1, sigma=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  3,  7,  4,  6,  1,  4,  3, 13, 11, 13, 11,  6,  9,  7,  5,  4,\n",
       "       13, 11,  0,  9,  0,  7,  6,  9, 15,  5,  3,  5,  8,  8,  5, 12,  9,\n",
       "       15,  7,  1, 11, 14, 11, 11, 13, 11,  7,  9, 10, 14,  5,  3,  5, 12,\n",
       "        7,  9,  4,  6, 12, 10, 12,  5, 12, 11, 14,  8, 12, 11,  5,  8,  0,\n",
       "       10, 12,  4,  8,  9, 12, 10,  9,  8,  6, 12, 11,  9,  9, 10,  9,  9,\n",
       "       12,  3,  5,  2, 11, 18, 23, 25, 24, 21, 30, 16, 23, 23, 19, 21, 19,\n",
       "       29, 28, 27, 24, 19, 26, 25, 20, 25, 23, 24, 25, 25, 30, 21, 24, 26,\n",
       "       25, 18, 24, 26, 21, 27, 26, 29, 21, 21, 19, 30, 26, 21, 25, 24, 29,\n",
       "       20, 19, 26, 19, 29, 26, 20, 23, 20, 29, 23, 17, 16, 28, 24, 16, 25,\n",
       "       28, 23, 28, 24, 26, 28, 16, 23, 24, 21, 18, 24, 25, 24, 24, 24, 22,\n",
       "       23, 23, 22, 28, 19, 27, 21, 24, 22, 27], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colors_hashed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180\n"
     ]
    }
   ],
   "source": [
    "import scipy as sp\r\n",
    "import log_primes_list as log_pl\r\n",
    "hashed_attributes = colors_hashed\r\n",
    "# Create one empty feature vector for each graph\r\n",
    "feature_vectors = []\r\n",
    "for _ in X:\r\n",
    "    feature_vectors.append(np.zeros(0, dtype=np.float64))\r\n",
    "\r\n",
    "# Construct block diagonal matrix of all adjacency matrices\r\n",
    "adjacency_matrices = []\r\n",
    "for g in X:\r\n",
    "    adjacency_matrices.append(np.array(nx.adjacency_matrix(g).todense()))\r\n",
    "M = sp.sparse.block_diag(tuple(adjacency_matrices), dtype=np.float64, format=\"csr\")\r\n",
    "num_vertices = M.shape[0]\r\n",
    "print(num_vertices)\r\n",
    "\r\n",
    "# Load list of precalculated logarithms of prime numbers\r\n",
    "log_primes = log_pl.log_primes[0:num_vertices]\r\n",
    "\r\n",
    "# Color vector representing labels\r\n",
    "colors_0 = np.zeros(num_vertices, dtype=np.float64)\r\n",
    "# Color vector representing hashed attributes\r\n",
    "colors_1 = hashed_attributes\r\n",
    "\r\n",
    "# Get labels (colors) from all graph instances\r\n",
    "offset = 0\r\n",
    "graph_indices = []\r\n",
    "\r\n",
    "\r\n",
    "for g in graph_db:\r\n",
    "    if False:\r\n",
    "        for i, label in enumerate(nx.get_node_attributes(g,label_name).values()):\r\n",
    "            colors_0[i + offset] = label\r\n",
    "\r\n",
    "    graph_indices.append((offset, offset + g.num_vertices() - 1))\r\n",
    "    offset += g.num_vertices()\r\n",
    "\r\n",
    "# Map labels to [0, number_of_colors)\r\n",
    "if False:\r\n",
    "    _, colors_0 = np.unique(colors_0, return_inverse=True)\r\n",
    "\r\n",
    "for it in range(0, iterations + 1):\r\n",
    "\r\n",
    "    if False:\r\n",
    "        # Map colors into a single color vector\r\n",
    "        colors_all = np.array([colors_0, colors_1])\r\n",
    "        colors_all = [hash(tuple(row)) for row in colors_all.T]\r\n",
    "        _, colors_all = np.unique(colors_all, return_inverse=True)\r\n",
    "        max_all = int(np.amax(colors_all) + 1)\r\n",
    "        # max_all = int(np.amax(colors_0) + 1)\r\n",
    "\r\n",
    "        feature_vectors = [\r\n",
    "            np.concatenate((feature_vectors[i], np.bincount(colors_all[index[0]:index[1] + 1], minlength=max_all)))\r\n",
    "            for i, index in enumerate(graph_indices)]\r\n",
    "\r\n",
    "        # Avoid coloring computation in last iteration\r\n",
    "        if it < iterations:\r\n",
    "            colors_0 = compute_coloring(M, colors_0, log_primes[0:len(colors_0)])\r\n",
    "            colors_1 = compute_coloring(M, colors_1, log_primes[0:len(colors_1)])\r\n",
    "    else:\r\n",
    "        max_1 = int(np.amax(colors_1) + 1)\r\n",
    "\r\n",
    "        feature_vectors = [\r\n",
    "            np.concatenate((feature_vectors[i], np.bincount(colors_1[index[0]:index[1] + 1], minlength=max_1))) for\r\n",
    "            i, index in enumerate(graph_indices)]\r\n",
    "\r\n",
    "        # Avoid coloring computation in last iteration\r\n",
    "        if it < iterations:\r\n",
    "            colors_1 = compute_coloring(M, colors_1, log_primes[0:len(colors_1)])\r\n",
    "\r\n",
    "# if not compute_gram_matrix:\r\n",
    "#     return lil.lil_matrix(feature_vectors, dtype=np.float64)\r\n",
    "# else:\r\n",
    "#     # Make feature vectors sparse\r\n",
    "#     gram_matrix = csr.csr_matrix(feature_vectors, dtype=np.float64)\r\n",
    "#     # Compute gram matrix\r\n",
    "#     gram_matrix = gram_matrix.dot(gram_matrix.T)\r\n",
    "\r\n",
    "#     gram_matrix = gram_matrix.toarray()\r\n",
    "\r\n",
    "#     if normalize_gram_matrix:\r\n",
    "#         return aux.normalize_gram_matrix(gram_matrix)\r\n",
    "#     else:\r\n",
    "#         return gram_matrix"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "73a028860b43d4769fbff148c75133d75a7cd8af5513f33c83e2292b4997b353"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit ('.venv': venv)",
   "name": ".venv"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}